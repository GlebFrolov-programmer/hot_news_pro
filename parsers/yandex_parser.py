import json
import os
import time
from abc import ABC
from datetime import datetime
from typing import List, Dict, Optional
import pandas as pd

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è Yandex API
from yandex_cloud_ml_sdk import YCloudML

from parsers.base_parser import BaseParser
from news.news_item import NewsItem
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type, RetryError


class YandexParser(BaseParser, ABC):
    def __init__(self, requests_to_parse: list[str], parameters: dict, metadata: dict, save_to: dict):
        super().__init__()
        self.class_name = 'Yandex'
        self.requests_to_parse = requests_to_parse
        self.metadata = metadata
        self.parameters = parameters
        self.sdk = None
        self.search_api = None

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Yandex SDK
        self.init_yandex_sdk()

        try:
            self.raw_data = [i for i in list(set(self.parse()))]
        except RetryError as e:
            print(f"Parsing failed after retries: {e}, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.")
            self.raw_data = []
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            self.raw_data = []

        self.save_to = save_to

        if save_to['TO_EXCEL']:
            self.to_excel()
        if save_to['TO_JSON']:
            self.to_json()
        self.print_statistics()

    @property
    def class_name(self) -> str:
        return self._class_name

    @class_name.setter
    def class_name(self, value: str):
        self._class_name = value

    @property
    def raw_data(self) -> list:
        return self._raw_data

    @raw_data.setter
    def raw_data(self, value: list):
        self._raw_data = value

    @property
    def requests_to_parse(self) -> list[str]:
        return self._requests_to_parse

    @requests_to_parse.setter
    def requests_to_parse(self, value: list[str]):
        self._requests_to_parse = value

    @property
    def metadata(self) -> dict:
        return self._metadata

    @metadata.setter
    def metadata(self, value: dict):
        self._metadata = value

    @property
    def parameters(self) -> dict:
        return self._parameters

    @parameters.setter
    def parameters(self, value: dict):
        self._parameters = value

    def init_yandex_sdk(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Yandex Cloud ML SDK"""
        try:
            print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Yandex Search API...")

            # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            folder_id = self.parameters['AUTHENTICATION']['YANDEX_FOLDER_ID']
            auth_token = self.parameters['AUTHENTICATION']['YANDEX_AUTH_API']
            user_agent = self.parameters.get('USER_AGENT',
                                             "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 YaBrowser/25.2.0.0 Safari/537.36")

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SDK
            self.sdk = YCloudML(
                folder_id=folder_id,
                auth=auth_token
            )

            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            # self.sdk.setup_default_logging("error")

            # –°–æ–∑–¥–∞–Ω–∏–µ Search API –æ–±—ä–µ–∫—Ç–∞
            self.search_api = self.sdk.search_api.web(
                search_type=self.parameters.get('SEARCH_TYPE', 'ru'),
                user_agent=user_agent,
            )

            print("‚úÖ Yandex Search API –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Yandex SDK: {e}")
            raise

    def perform_api_search(self, query: str, page: int = 0) -> Optional[str]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ Yandex API"""
        try:
            print(f"üîç API –ø–æ–∏—Å–∫: '{query}' (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page + 1})")

            # –ü–æ–ª—É—á–∞–µ–º —Ñ–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            format = self.parameters.get('RESULT_FORMAT', 'xml')

            # –í—ã–ø–æ–ª–Ω—è–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ API
            operation = self.search_api.run_deferred(query, format=format, page=page)

            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–∏
            print("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç API...")
            search_result = operation.wait(poll_interval=1)

            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result_content = search_result.decode('utf-8')

            return result_content

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ API –ø–æ–∏—Å–∫–µ '{query}': {e}")
            return None

    def parse_xml_response(self, api_response: str) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ XML –æ—Ç–≤–µ—Ç–∞ –æ—Ç API"""
        results = []

        try:
            from xml.etree import ElementTree as ET

            # –ü–∞—Ä—Å–∏–º XML
            root = ET.fromstring(api_response)

            # –ò—â–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞
            for doc in root.findall('.//doc'):
                result = {}

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                title_elem = doc.find('title')
                if title_elem is not None and title_elem.text:
                    result['title'] = title_elem.text.strip()

                # –ò–∑–≤–ª–µ–∫–∞–µ–º URL
                url_elem = doc.find('url')
                if url_elem is not None and url_elem.text:
                    result['url'] = url_elem.text.strip()

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É, –µ—Å–ª–∏ –µ—Å—Ç—å
                date_elem = doc.find('date')
                if date_elem is not None and date_elem.text:
                    result['date'] = date_elem.text.strip()

                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ URL
                if result.get('title') and result.get('url'):
                    results.append(result)

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ XML: {e}")

        return results

    def parse_html_response(self, api_response: str) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ HTML –æ—Ç–≤–µ—Ç–∞ –æ—Ç API"""
        results = []

        try:
            from bs4 import BeautifulSoup

            soup = BeautifulSoup(api_response, 'html.parser')

            # –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ HTML
            result_divs = soup.find_all('div', class_='serp-item') or soup.find_all('li', class_='serp-item')

            for div in result_divs:
                result = {}

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Å—Å—ã–ª–∫—É
                title_elem = div.find('h2') or div.find('a', class_='OrganicTitle-Link')
                if title_elem:
                    title_text = title_elem.get_text(strip=True)
                    if title_text:
                        result['title'] = title_text

                    url = title_elem.get('href', '')
                    if url:
                        result['url'] = url

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É
                date_elem = div.find('span', class_='datetime')
                if date_elem:
                    date_text = date_elem.get_text(strip=True)
                    if date_text:
                        result['date'] = date_text

                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ URL
                if result.get('title') and result.get('url'):
                    results.append(result)

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML: {e}")

        return results

    def parse_api_response(self, api_response: str) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –æ—Ç API –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞"""
        format = self.parameters.get('RESULT_FORMAT', 'xml').lower()

        if format == 'xml':
            return self.parse_xml_response(api_response)
        elif format == 'html':
            return self.parse_html_response(api_response)
        else:
            print(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: {format}")
            return []

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=8, max=15),
        retry=retry_if_exception_type((Exception,))
    )
    def parse(self) -> list[NewsItem]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Yandex API"""

        print(f'\nüîé YANDEX API SCRAPING {self.metadata}')

        if not self.search_api:
            raise Exception("Search API –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

        news_items = []
        total_queries = len(self.requests_to_parse)

        for i, request in enumerate(self.requests_to_parse, 1):
            query = request['query'] if isinstance(request, dict) else request

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª–∏–º–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            if isinstance(request, dict) and 'search_limit' in request:
                max_results = request['search_limit']
            else:
                max_results = self.parameters.get('SEARCH_LIMIT_YANDEX', 15)

            print(f'    [{i}/{total_queries}] QUERY: {query}')
            print(f'    –õ–∏–º–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {max_results}')

            try:
                all_results = []
                page = 0

                # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
                while len(all_results) < max_results:
                    page += 1
                    print(f"      üìñ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}")

                    # –í—ã–ø–æ–ª–Ω—è–µ–º API –∑–∞–ø—Ä–æ—Å
                    api_response = self.perform_api_search(query, page - 1)

                    if not api_response:
                        print(f"      ‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç API")
                        break

                    # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
                    page_results = self.parse_api_response(api_response)

                    # –§–∏–ª—å—Ç—Ä—É–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ URL
                    unique_urls = set()
                    filtered_results = []

                    for result in page_results:
                        url = result.get('url', '')
                        if url and url not in unique_urls:
                            unique_urls.add(url)
                            filtered_results.append(result)

                    all_results.extend(filtered_results)

                    print(f"      üìä –ù–∞–π–¥–µ–Ω–æ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {len(filtered_results)}")
                    print(f"      üìä –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {len(all_results)}")

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç
                    if len(all_results) >= max_results:
                        all_results = all_results[:max_results]
                        print(f"      ‚úÖ –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –≤ {max_results} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                        break

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –µ—â–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    if len(page_results) == 0:
                        print(f"      ‚ö†Ô∏è –ë–æ–ª—å—à–µ –Ω–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                        break

                    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
                    time.sleep(1)

                # –°–æ–∑–¥–∞–µ–º NewsItem –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                for j, result in enumerate(all_results, 1):
                    title = result.get('title', '')
                    url = result.get('url', '')

                    if title and url:
                        news_items.append(
                            NewsItem(
                                source=self.class_name,
                                metadata=self.metadata,
                                url=url,
                                title=title,
                                approved=self.check_approved_source(url)
                            )
                        )
                        print(f"        {j}. {title[:70]} {url}...")

                print(f"      ‚úÖ –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(all_results)}")

            except Exception as e:
                print(f"Error processing query '{query}': {e}")
                raise e

            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            if i < total_queries:
                print(f"      ‚è≥ –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏: 2 —Å–µ–∫...")
                time.sleep(2)

        return news_items